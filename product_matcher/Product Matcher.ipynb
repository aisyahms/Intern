{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "owned-nashville",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install -q -U tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "greater-clarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.image import imread\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tripletloss_preprocessing import PreProcessing\n",
    "from tripletloss_model import TripletLoss\n",
    "from tripletloss_prediction import show_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "saved-jamaica",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'trained_model/model_triplet/'\n",
    "model = TripletLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "criminal-fetish",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aisyah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\convolutional.py:414: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  warnings.warn('`tf.layers.conv2d` is deprecated and '\n",
      "C:\\Users\\Aisyah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "C:\\Users\\Aisyah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\core.py:329: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# Input and Output Tensor\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "img_placeholder = tf.compat.v1.placeholder(tf.float32, [None, 28, 28, 3], name='img')\n",
    "net = model.conv_net(img_placeholder, reuse=False) # from TripletLoss class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-dallas",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Retail Corpus Dataset...\n"
     ]
    }
   ],
   "source": [
    "train_images, valid_images, train_label, valid_label = PreProcessing('retail_corpus/').preprocessing(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lined-phase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to plot image\n",
    "def show_image(idxs, data):\n",
    "    if type(idxs) != np.ndarray:\n",
    "        idxs = np.array([idxs]) # 2d array\n",
    "    fig = plt.figure()\n",
    "    gs = gridspec.GridSpec(1,len(idxs))\n",
    "    for i in range(len(idxs)): # iterate through image indexes\n",
    "        ax = fig.add_subplot(gs[0,i])\n",
    "        ax.imshow(data[idxs[i],:,:,:])\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random index from valid_images corpus and display the image\n",
    "idx = np.random.randint(0, len(valid_images))\n",
    "img = valid_images[idx]\n",
    "\n",
    "print(\"********** QUERY IMAGE **********\")\n",
    "show_image(idx, valid_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-large",
   "metadata": {},
   "source": [
    "### Finding k-nearest neighbours (k most similar images) using cosine similarity\n",
    "Note: \n",
    "- there is a library that will facilitate a faster and more efficient similarity search called `faiss` but it is an 'Unofficial prebuilt binary for Linux and MacOS' only.\n",
    "- The CPU-only faiss-cpu conda package is currently available on Linux, OSX, and Windows. The faiss-gpu, containing both CPU and GPU indices, is available on Linux systems, for various versions of CUDA. https://github.com/facebookresearch/faiss/blob/master/INSTALL.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-whale",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute vector representation for each training image and normalise \n",
    "def generate_norm_vectors():\n",
    "    saver = tf.compat.v1.train.Saver()\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        sess.run(tf.compat.v1.global_variables_initializer())\n",
    "        ckpt = tf.train.get_checkpoint_state(model_path) # model_path defined earlier as model_triplet\n",
    "        saver.restore(sess, model_path + \"model.ckpt\")\n",
    "        train_vectors = sess.run(net, feed_dict={img_placeholder:train_images})      \n",
    "    normalized_train_vectors = train_vectors/np.linalg.norm(train_vectors,axis=1).reshape(-1,1) # reshape array into 2d array regardless of original shape\n",
    "    return normalized_train_vectors\n",
    "\n",
    "# Find k nearest neighbours using cos similarity\n",
    "def find_k_nn(normalized_train_vectors,vec,k):\n",
    "    dist_arr = np.matmul(normalized_train_vectors, vec.T)\n",
    "    return np.argsort(-dist_arr.flatten())[:k] # in descending order of similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_training_vectors = generate_norm_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute vector representation of valid image \n",
    "saver = tf.compat.v1.train.Saver()\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    ckpt = tf.train.get_checkpoint_state(model_path)\n",
    "    saver.restore(sess, model_path + \"model.ckpt\")\n",
    "    search_vector = sess.run(net, feed_dict={img_placeholder:[img]}) # defined before knn section   \n",
    "normalized_search_vec = search_vector/np.linalg.norm(search_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_time = time.time()\n",
    "k = 10 # k most similar images\n",
    "candidate_index = find_k_nn(norm_training_vectors, normalized_search_vec, k)\n",
    "print('Total time to find NNs: {:0.2f} ms'.format((time.time()-s_time)*1000)) # current time - time started\n",
    "fig = plt.figure(figsize=(10,0.8))\n",
    "idxs = [idx]\n",
    "gs = gridspec.GridSpec(1, len(idxs))\n",
    "\n",
    "# plot test image\n",
    "for i in range(len(idxs)):\n",
    "    ax = fig.add_subplot(gs[0, i]) # all in a row\n",
    "    ax.imshow(valid_images[idxs[i], :, :, :])\n",
    "    ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# plot similar images\n",
    "show_image(candidate_index, train_images)\n",
    "print(\"Index of Similar Images:\", candidate_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to plot multiple images\n",
    "def show_top_k_images(indx_list,valid_image_indexes, train_data, valid_data):\n",
    "    fig = plt.figure(figsize=(20,40))\n",
    "    gs = gridspec.GridSpec(len(indx_list),len(indx_list[0])+2)\n",
    "    for i in range(len(indx_list)):\n",
    "        ax = fig.add_subplot(gs[i,0]) # each row different image query\n",
    "        ax.imshow(valid_data[valid_image_indexes[i],:,:,:])\n",
    "        ax.axis('off')\n",
    "        for j in range(len(indx_list[0])): # for each image query, show its similar images\n",
    "            ax = fig.add_subplot(gs[i,j+2])\n",
    "            ax.imshow(train_data[indx_list[i][j],:,:,:])\n",
    "            ax.axis('off')\n",
    "    plt.savefig('figures/similar_images.jpg') \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "N = 20\n",
    "indx_list = []\n",
    "valid_image_indexes = []\n",
    "_valid_images = []\n",
    "for i in range(N):\n",
    "    idx = i\n",
    "    valid_image_indexes.append(idx)\n",
    "    _valid_images.append(valid_images[idx])\n",
    "    # run the test image through the network to get the test features\n",
    "saver = tf.compat.v1.train.Saver()\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    ckpt = tf.train.get_checkpoint_state(model_path)\n",
    "    saver.restore(sess, model_path + \"model.ckpt\")\n",
    "    search_vectors = sess.run(net, feed_dict={img_placeholder:_valid_images})\n",
    "    \n",
    "normalized_search_vecs = search_vectors/np.linalg.norm(search_vectors,axis=1).reshape(-1,1)\n",
    "for i in range(len(normalized_search_vecs)):\n",
    "    candidate_index = find_k_nn(norm_training_vectors, normalized_search_vecs[i], K)\n",
    "    indx_list.append(candidate_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('** Query Image **         *************************** Top {} Similar Images  ***************************'.format(K))\n",
    "show_top_k_images(indx_list,valid_image_indexes, train_images, valid_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-alloy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-taiwan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-diagram",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-progress",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-arrangement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "clear-juice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[140, 150, 156, 255],\n",
       "        [156, 166, 164, 255],\n",
       "        [148, 158, 164, 255],\n",
       "        ...,\n",
       "        [ 52,  50,  52, 255],\n",
       "        [ 52,  50,  52, 255],\n",
       "        [ 68,  66,  68, 255]],\n",
       "\n",
       "       [[140, 150, 156, 255],\n",
       "        [156, 158, 164, 255],\n",
       "        [148, 158, 164, 255],\n",
       "        ...,\n",
       "        [ 52,  50,  52, 255],\n",
       "        [ 52,  50,  52, 255],\n",
       "        [ 68,  66,  68, 255]],\n",
       "\n",
       "       [[140, 150, 156, 255],\n",
       "        [148, 166, 164, 255],\n",
       "        [148, 158, 164, 255],\n",
       "        ...,\n",
       "        [ 52,  50,  52, 255],\n",
       "        [ 52,  50,  52, 255],\n",
       "        [ 76,  66,  68, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 44,  34,  28, 255],\n",
       "        [ 36,  22,  12, 255],\n",
       "        [ 44,  34,  28, 255],\n",
       "        ...,\n",
       "        [ 44,  34,  28, 255],\n",
       "        [ 44,  34,  28, 255],\n",
       "        [ 44,  34,  28, 255]],\n",
       "\n",
       "       [[ 44,  42,  36, 255],\n",
       "        [ 36,  22,  12, 255],\n",
       "        [ 36,  22,  12, 255],\n",
       "        ...,\n",
       "        [ 44,  34,  28, 255],\n",
       "        [ 44,  34,  28, 255],\n",
       "        [ 44,  34,  28, 255]],\n",
       "\n",
       "       [[ 44,  34,  28, 255],\n",
       "        [ 36,  22,  12, 255],\n",
       "        [ 44,  34,  28, 255],\n",
       "        ...,\n",
       "        [ 44,  34,  28, 255],\n",
       "        [ 44,  34,  28, 255],\n",
       "        [ 44,  34,  28, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matplotlib.image.imread(os.path.join('retail_corpus/Office Reception Sofas/','22209_contemporary_group-1a_2.gif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "military-blues",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sofa': 0, 'table': 1, 'lamp': 2}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(['sofa', 'table','lamp'], range(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "healthy-puzzle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 9]]\n"
     ]
    }
   ],
   "source": [
    "idxs = [1,1,9]\n",
    "if type(idxs) != np.ndarray:\n",
    "    idxs = np.array([idxs])\n",
    "    print(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-producer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
